{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([1, 12])\n",
      "Number of output tokens?:  10\n",
      "Number of layers:  17\n",
      "Number of layers:  17\n",
      "Number of layers:  17\n",
      "First token:  torch.Size([1, 12, 2048])\n",
      "Second token:  torch.Size([1, 1, 2048])\n",
      "Third token:  torch.Size([1, 1, 2048])\n",
      "===\n",
      "First token:  tensor([ 0.1540, -0.5038,  1.6057,  ..., -0.2343,  1.3638, -0.1373])\n",
      "Second token:  tensor([ 0.0608, -0.1365, -0.1327,  ...,  0.0287, -0.0818, -0.0287])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llm_toolkit.llm import LLM\n",
    "\n",
    "llm = LLM(\"unsloth/Llama-3.2-1B-Instruct\")\n",
    "inputs = llm.tokenizer(\"This is my test, yes, my very test.\", return_tensors=\"pt\")\n",
    "print(f\"Inputs: {inputs['input_ids'].shape}\")\n",
    "with torch.no_grad():\n",
    "    outputs = llm.model.generate(inputs.input_ids, \n",
    "                                    output_hidden_states=True, \n",
    "                                    return_dict_in_generate=True, \n",
    "                                    max_new_tokens=10, \n",
    "                                    min_new_tokens=10, \n",
    "                                    pad_token_id=llm.tokenizer.pad_token_id)\n",
    "    \n",
    "\n",
    "print(\"Number of output tokens?: \", len(outputs['hidden_states']))\n",
    "print(\"Number of layers: \", len(outputs['hidden_states'][0]))\n",
    "print(\"Number of layers: \", len(outputs['hidden_states'][1]))\n",
    "print(\"Number of layers: \", len(outputs['hidden_states'][2]))\n",
    "print(\"First token: \", outputs['hidden_states'][0][5].shape) # Layer 5 - contains all the tokens from input?\n",
    "print(\"Second token: \", outputs['hidden_states'][1][5].shape) # Layer 5\n",
    "print(\"Third token: \", outputs['hidden_states'][2][5].shape) # Layer 5\n",
    "print(\"===\")\n",
    "print(\"First token: \", outputs['hidden_states'][0][5][0,0,:])\n",
    "print(\"Second token: \", outputs['hidden_states'][0][5][0,1,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.68554688e-03,  3.08227539e-03, -6.80541992e-03, ...,\n",
       "          1.07574463e-03,  8.20159912e-04,  1.54876709e-03],\n",
       "        [-3.54003906e-03, -2.06298828e-02,  1.75781250e-02, ...,\n",
       "         -2.13623047e-03, -1.91650391e-02, -1.58691406e-02],\n",
       "        [ 1.03149414e-02,  1.96533203e-02,  2.19726562e-02, ...,\n",
       "         -1.19018555e-02,  6.34765625e-03,  8.23974609e-03],\n",
       "        ...,\n",
       "        [-1.94549561e-03, -5.12695312e-03,  2.41699219e-02, ...,\n",
       "         -3.14331055e-03, -4.02832031e-03, -2.20947266e-02],\n",
       "        [ 3.06701660e-03,  1.08642578e-02,  3.05175781e-02, ...,\n",
       "          4.39453125e-02,  2.70996094e-02, -1.95312500e-02],\n",
       "        [-1.20239258e-02, -2.24609375e-02,  2.89306641e-02, ...,\n",
       "         -2.63671875e-02, -2.02636719e-02,  7.44628906e-03]],\n",
       "\n",
       "       [[ 2.01542228e-02, -4.58822101e-02,  5.11894748e-02, ...,\n",
       "         -1.37398615e-02,  5.68491109e-02,  6.34422153e-03],\n",
       "        [ 3.51454467e-02, -1.44961728e-02, -7.65948370e-02, ...,\n",
       "          4.59279418e-02, -3.84887755e-02,  2.34981664e-02],\n",
       "        [ 3.34146470e-02,  7.28176162e-03, -7.75787886e-03, ...,\n",
       "         -1.62367169e-02,  1.13946591e-02,  9.68639739e-03],\n",
       "        ...,\n",
       "        [-1.95439346e-03, -3.42318341e-02, -1.08507246e-01, ...,\n",
       "         -1.39569836e-02,  5.91650233e-02, -6.49386942e-02],\n",
       "        [ 4.93566133e-03,  1.33917248e-02, -2.69207470e-02, ...,\n",
       "          6.17663451e-02,  1.04265921e-02, -1.69363506e-02],\n",
       "        [-1.29704624e-02, -2.62304526e-02,  9.45178326e-03, ...,\n",
       "         -1.29657770e-02, -1.15887532e-02,  7.71294627e-03]],\n",
       "\n",
       "       [[ 1.32177919e-01, -4.83676255e-01,  1.58605564e+00, ...,\n",
       "         -2.56756902e-01,  1.34961236e+00, -1.13982365e-01],\n",
       "        [ 4.44352105e-02, -3.93691212e-02, -1.14518248e-01, ...,\n",
       "          3.50716710e-02, -4.83381860e-02, -1.47639886e-02],\n",
       "        [ 1.88734680e-02, -1.64549574e-02, -4.78219613e-02, ...,\n",
       "          2.29398366e-02,  2.85716821e-02,  1.68399662e-02],\n",
       "        ...,\n",
       "        [ 3.71868908e-02, -5.34380749e-02, -1.22363046e-01, ...,\n",
       "         -2.10703500e-02,  7.16625303e-02, -8.54082853e-02],\n",
       "        [ 5.47741279e-02, -3.24256085e-02, -3.24202478e-02, ...,\n",
       "          7.04960153e-02, -1.70469172e-02, -1.71705279e-02],\n",
       "        [-2.27381326e-02, -2.51654442e-02,  1.59290582e-02, ...,\n",
       "         -1.56381838e-02, -3.68264951e-02, -6.03911187e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.61425102e-02, -3.52657229e-01,  1.14541292e+00, ...,\n",
       "         -2.38138989e-01,  8.28988135e-01,  3.55178043e-02],\n",
       "        [ 7.87221789e-02, -8.95790085e-02, -8.97555798e-02, ...,\n",
       "         -2.26027653e-01, -3.54502678e-01, -1.22208223e-02],\n",
       "        [ 1.80524170e-01, -2.01246560e-01, -7.45566711e-02, ...,\n",
       "         -2.24871654e-02, -2.79204786e-01, -1.97808087e-01],\n",
       "        ...,\n",
       "        [-2.33987309e-02,  3.02013457e-01, -1.93894103e-01, ...,\n",
       "          4.33377266e-01,  7.83147365e-02, -2.12078720e-01],\n",
       "        [ 1.01698503e-01, -7.46179596e-02, -1.00103453e-01, ...,\n",
       "          2.81916678e-01, -2.88355052e-01, -2.54412949e-01],\n",
       "        [-1.11989491e-01,  2.29602933e-01,  1.73065871e-01, ...,\n",
       "         -2.25452706e-01,  1.53866364e-02, -2.40032412e-02]],\n",
       "\n",
       "       [[ 9.11268890e-02, -8.23899925e-01,  1.43060422e+00, ...,\n",
       "          2.52611667e-01,  6.50789499e-01,  2.75907189e-01],\n",
       "        [ 8.32092464e-02, -2.61868387e-01, -1.44232482e-01, ...,\n",
       "         -4.30346191e-01, -4.50770617e-01, -1.30277276e-01],\n",
       "        [ 1.17310449e-01, -1.29836082e-01, -5.25545143e-02, ...,\n",
       "         -7.70627409e-02, -3.65426391e-01, -2.60699183e-01],\n",
       "        ...,\n",
       "        [ 2.27177963e-02,  3.17876816e-01, -4.91002351e-02, ...,\n",
       "          4.65063334e-01,  2.31572315e-02, -3.66391718e-01],\n",
       "        [ 2.85375923e-01,  3.50951031e-02, -4.55586948e-02, ...,\n",
       "          9.51327831e-02, -3.65213603e-01, -3.27460140e-01],\n",
       "        [-2.48124167e-01,  2.68348277e-01,  3.33689332e-01, ...,\n",
       "         -2.75800675e-01, -3.53732742e-02, -1.19433813e-01]],\n",
       "\n",
       "       [[ 9.76232708e-01,  1.80434510e-01,  6.17888987e-01, ...,\n",
       "         -8.41963589e-01, -2.70080209e-01,  5.89551963e-02],\n",
       "        [ 1.38336837e+00,  3.52623641e-01,  8.93808961e-01, ...,\n",
       "         -4.45138979e+00, -5.05387783e+00,  5.05196452e-01],\n",
       "        [ 8.86011243e-01,  1.69982314e+00,  1.01790226e+00, ...,\n",
       "         -4.38280630e+00, -5.17398214e+00,  5.17485201e-01],\n",
       "        ...,\n",
       "        [-5.96156538e-01,  3.92434978e+00,  6.79364622e-01, ...,\n",
       "          7.46252954e-01, -3.07671690e+00, -1.52854192e+00],\n",
       "        [-1.55126881e-02,  3.74250460e+00,  2.07125211e+00, ...,\n",
       "         -2.09261537e+00, -3.22157240e+00, -4.61908430e-01],\n",
       "        [-1.95014358e+00,  4.06860495e+00,  1.41599405e+00, ...,\n",
       "         -6.08121872e+00, -1.06953943e+00,  8.20065439e-01]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "num_layers = len(outputs['hidden_states'][0])  # Number of layers\n",
    "sequence_length = outputs['hidden_states'][0][0].shape[1]  # Sequence length\n",
    "embedding_dim = outputs['hidden_states'][0][0].shape[2]  # Embedding dimension\n",
    "\n",
    "embeddings = np.zeros((num_layers, sequence_length, embedding_dim))\n",
    "\n",
    "token_index_list: list[str] = []\n",
    "# Iterate over each layer and token to extract embeddings\n",
    "for token_index in range(sequence_length):\n",
    "    for layer_index in range(num_layers):\n",
    "        embeddings[layer_index, token_index, :] = outputs['hidden_states'][0][layer_index][0, token_index, :].detach().numpy()\n",
    "        token_index_list.append(token_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-Toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
